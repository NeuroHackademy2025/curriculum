{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc78096-fcd6-4577-a0e9-6d3efc8cd56b",
   "metadata": {},
   "source": [
    "# Putting it together: General Linear Models for Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c6b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nilearn import datasets\n",
    "\n",
    "os.environ[\"NILEARN_SHARED_DATA\"] = \"~/shared/data/nilearn_data\"\n",
    "datasets.get_data_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555a46c-1163-4716-b58f-baacdf75e14f",
   "metadata": {},
   "source": [
    "Full step-by-step example of fitting a GLM to perform a decoding experiment.\n",
    "In this decoding analysis, we will be doing a one-vs-all classification.\n",
    "We use the data from one subject of the Haxby dataset.\n",
    "\n",
    "More specifically, we will:\n",
    "* Download the Haxby dataset.\n",
    "* Extract the information to generate a glm representing the blocks of stimuli.\n",
    "* Analyze the decoding performance using a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e02c8a-6ef7-4983-b4e6-6066a1297e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nilearn.datasets import fetch_haxby\n",
    "\n",
    "haxby_dataset = fetch_haxby(subjects=(3,))\n",
    "\n",
    "# set TR in seconds, following information in the original paper\n",
    "t_r = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d485e3-7012-4b71-bfc3-18d561dcda3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target information as string \n",
    "behavior = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "\n",
    "unique_conditions = behavior[\"labels\"].unique()\n",
    "conditions = behavior[\"labels\"].values\n",
    "\n",
    "runs = behavior[\"chunks\"].to_numpy()\n",
    "unique_runs = behavior[\"chunks\"].unique()\n",
    "\n",
    "# events will take the form of a dictionary of Dataframes, one per run\n",
    "events = {}\n",
    "\n",
    "for run in unique_runs:\n",
    "\n",
    "    # get the condition label per run\n",
    "    conditions_run = conditions[runs == run]\n",
    "\n",
    "    # get the number of scans per run, then the corresponding\n",
    "    # vector of frame times\n",
    "    n_scans = len(conditions_run)\n",
    "    frame_times = t_r * np.arange(n_scans)\n",
    "\n",
    "    # each event last the full TR\n",
    "    duration = t_r * np.ones(n_scans)\n",
    "\n",
    "    # Define the events object\n",
    "    events_ = pd.DataFrame(\n",
    "        {\n",
    "            \"onset\": frame_times,\n",
    "            \"trial_type\": conditions_run,\n",
    "            \"duration\": duration,\n",
    "        }\n",
    "    )\n",
    "    # remove the rest condition and insert into the dictionary\n",
    "    # this will be our baseline in the GLM, so we don't want to model it as a condition\n",
    "    events[run] = events_[events_.trial_type != \"rest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f7517-7c9c-458c-ad41-e1e88184b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import index_img\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "# Instantiate the glm\n",
    "glm = FirstLevelModel(\n",
    "    t_r=t_r,\n",
    "    mask_img=haxby_dataset.mask,\n",
    "    high_pass=0.008,\n",
    "    smoothing_fwhm=4,\n",
    ")\n",
    "\n",
    "z_maps = []\n",
    "conditions_label = []\n",
    "run_label = []\n",
    "\n",
    "for run in unique_runs:\n",
    "    # grab the fmri data for that particular run\n",
    "    fmri_run = index_img(haxby_dataset.func[0], runs == run)\n",
    "\n",
    "    # fit the GLM\n",
    "    glm.fit(fmri_run, events=events[run])\n",
    "\n",
    "    # set up contrasts: one per condition\n",
    "    conditions = events[run].trial_type.unique()\n",
    "    for condition_ in conditions:\n",
    "        z_maps.append(glm.compute_contrast(condition_))\n",
    "        conditions_label.append(condition_)\n",
    "        run_label.append(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbbe56c-24ed-4eac-977a-9cc5dbd6ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "from nilearn.decoding import Decoder\n",
    "\n",
    "decoder = Decoder(\n",
    "    estimator=\"svc\",\n",
    "    mask=haxby_dataset.mask,\n",
    "    standardize=False,\n",
    "    screening_percentile=5,\n",
    "    cv=LeaveOneGroupOut(),\n",
    ")\n",
    "decoder.fit(z_maps, conditions_label, groups=run_label)\n",
    "\n",
    "# Return the corresponding mean prediction accuracy compared to chance\n",
    "# for classifying one-vs-all items.\n",
    "\n",
    "classification_accuracy = np.mean(list(decoder.cv_scores_.values()))\n",
    "chance_level = 1.0 / len(np.unique(conditions))\n",
    "print(\n",
    "    f\"Classification accuracy: {classification_accuracy:.4f} / \"\n",
    "    f\"Chance level: {chance_level}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e060a2e-a6f3-4ce2-864a-2e319364ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.coef_img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f29a9-1492-457f-9689-384df28e0c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.surface import SurfaceImage\n",
    "from nilearn.plotting import plot_surf_stat_map\n",
    "from nilearn.datasets import load_fsaverage, load_fsaverage_data\n",
    "\n",
    "fsaverage_meshes = load_fsaverage()\n",
    "\n",
    "surface_coef = SurfaceImage.from_volume(\n",
    "    mesh=fsaverage_meshes[\"pial\"],\n",
    "    volume_img=decoder.coef_img_['face'],\n",
    ")\n",
    "\n",
    "curv_sign = load_fsaverage_data(data_type=\"curvature\")\n",
    "for hemi, data in curv_sign.data.parts.items():\n",
    "    curv_sign.data.parts[hemi] = np.sign(data)\n",
    "\n",
    "plot_surf_stat_map(\n",
    "    surf_mesh=fsaverage_meshes[\"inflated\"],\n",
    "    stat_map=surface_coef,\n",
    "    bg_map=curv_sign,\n",
    "    hemi=\"both\",\n",
    "    view=\"ventral\",\n",
    "    threshold=0.0001,\n",
    "    darkness=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c157c-9bc3-4bd6-b111-d35503448ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import SurfaceMasker\n",
    "\n",
    "surf_masker = SurfaceMasker(cmap=\"viridis\").fit(surface_coef)\n",
    "report = surf_masker.generate_report()\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf94f70-5e74-4bd4-829c-06e307b03e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
