{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2897e3ea-287b-491b-af4d-4bf5dae1e3b3",
   "metadata": {},
   "source": [
    "# Statistical analysis in `nilearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ac5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3497fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nilearn import datasets\n",
    "\n",
    "os.environ[\"NILEARN_SHARED_DATA\"] = \"~/shared/data/nilearn_data\"\n",
    "datasets.get_data_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca0b9ce",
   "metadata": {},
   "source": [
    "In the previous examples, we've generated connectivity matrices as our features-of-interest for machine learning.\n",
    "However, there are many other kinds of relevant features we may want to extract from neuroimaging data.\n",
    "Alternatively, we may not be interested in doing machine learning at all,\n",
    "but instead performing statistical analysis using methods such as the General Linear Model (GLM).\n",
    "\n",
    "In this example, we'll perform a GLM analysis of a dataset provided by the Haxby Lab,\n",
    "in which participants were shown a number different categories of visual images.\n",
    "\n",
    "First, we need to download the dataset and its associated stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fea465-ffc2-4cb0-beeb-72d6bfdc43ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nilearn.datasets import fetch_haxby\n",
    "\n",
    "haxby_dataset = fetch_haxby(subjects=(2,), fetch_stimuli=True)\n",
    "print(haxby_dataset.description)\n",
    "\n",
    "# set TR in seconds, following information in the original paper\n",
    "t_r = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd5b81-67d7-4fc2-bdbb-0510e4b8b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "plotting.plot_roi(haxby_dataset.mask, bg_img=haxby_dataset.anat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0587b2-481e-477f-a763-195befdbcf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nilearn import image\n",
    "\n",
    "mean_img_ = image.mean_img(haxby_dataset.func[0], copy_header=True)\n",
    "plotting.plot_epi(mean_img_)\n",
    "\n",
    "n_trs = nib.load(haxby_dataset.func[0]).shape[-1]\n",
    "print(f\"There are {n_trs} TRs in the file {haxby_dataset.func[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3dd524-6f3c-4f8d-bc7b-cab5c6e27c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "key_stimuli = []\n",
    "exp_stimuli = []\n",
    "for key, values in haxby_dataset.stimuli.items():\n",
    "    key_stimuli.append(key)\n",
    "\n",
    "    try:\n",
    "        exp_stimuli.append(values[0])\n",
    "    except KeyError:\n",
    "        exp_stimuli.append(values['scrambled_faces'][0])\n",
    "\n",
    "# update naming convention of 'controls' to match labels in behavioral csv\n",
    "key_stimuli[4] = 'scrambledpix' \n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=8, figsize=(12, 12))\n",
    "# fig.suptitle(\"Example stimuli used in the experiment\")\n",
    "\n",
    "for img_path, img_categ, ax in zip(exp_stimuli, key_stimuli, axes.ravel()):\n",
    "    ax.imshow(plt.imread(img_path), cmap=\"gray\")\n",
    "    ax.set_title(img_categ)\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96f958",
   "metadata": {},
   "source": [
    "## Generate design matrices for each run\n",
    "\n",
    "Unlike in our previous connectivity analyses, we are now interested in known \"events\" that occurred throughout each run.\n",
    "These events correspond to the presentation of a different visual image.\n",
    "The presentation of each image is included as information in an accompanying CSV file.\n",
    "We will use this information to generate design matrices for each run to use in our GLM.\n",
    "\n",
    "Note in this case that all runs have been concatenated into a single nii file; the run identifier is indicated in the `chunk` label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e2aea-f6b5-464f-b414-e18434eb8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target information as string \n",
    "events = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8759725-7547-4c3a-9b2b-0cd1c500411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_conditions = events[\"labels\"].unique()\n",
    "conditions = events[\"labels\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a995d6d-c211-4c50-82e0-c1e761f34a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record these as an array of runs\n",
    "runs = events[\"chunks\"].to_numpy()\n",
    "unique_runs = events[\"chunks\"].unique()\n",
    "print(unique_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd836f-70da-4cf0-a334-50367994f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events will take the form of a dictionary of Dataframes, one per run\n",
    "events = {}\n",
    "\n",
    "for run in unique_runs:\n",
    "\n",
    "    # get the condition label per run\n",
    "    conditions_run = conditions[runs == run]\n",
    "\n",
    "    # get the number of scans per run, then the corresponding\n",
    "    # vector of frame times\n",
    "    n_scans = len(conditions_run)\n",
    "    frame_times = t_r * np.arange(n_scans)\n",
    "\n",
    "    # each event last the full TR\n",
    "    duration = t_r * np.ones(n_scans)\n",
    "\n",
    "    # Define the events object\n",
    "    events_ = pd.DataFrame(\n",
    "        {\n",
    "            \"onset\": frame_times,\n",
    "            \"trial_type\": conditions_run,\n",
    "            \"duration\": duration,\n",
    "        }\n",
    "    )\n",
    "    # remove the rest condition and insert into the dictionary\n",
    "    # this will be our baseline in the GLM, so we don't want to model it as a condition\n",
    "    events[run] = events_[events_.trial_type != \"rest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b790df-c27d-44e1-8b80-1b34ac4de625",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38d5aa8",
   "metadata": {},
   "source": [
    "## Run the GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f8b9ba-79aa-4095-99ad-1dc9c3d3e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "z_maps = []\n",
    "conditions_label = []\n",
    "run_label = []\n",
    "\n",
    "# Instantiate the glm\n",
    "glm = FirstLevelModel(\n",
    "    t_r=t_r,\n",
    "    mask_img=haxby_dataset.mask,\n",
    "    high_pass=0.008,\n",
    "    smoothing_fwhm=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562fbc0c-d97c-45b9-8013-eebce0993118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import index_img\n",
    "\n",
    "for run in unique_runs:\n",
    "    # grab the fmri data for that particular run\n",
    "    fmri_run = index_img(haxby_dataset.func[0], runs == run)\n",
    "\n",
    "    # fit the GLM\n",
    "    glm.fit(fmri_run, events=events[run])\n",
    "\n",
    "    # set up contrasts: one per condition\n",
    "    conditions = events[run].trial_type.unique()\n",
    "    for condition_ in conditions:\n",
    "        z_maps.append(glm.compute_contrast(condition_))\n",
    "        conditions_label.append(condition_)\n",
    "        run_label.append(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b4a5f-f200-41d4-aed9-6a8002e41de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = glm.generate_report(\n",
    "    contrasts=conditions,\n",
    "    bg_img=mean_img_,\n",
    ")\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
